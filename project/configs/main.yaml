
data_path: ./data/
results_path: ./results/

models:
  baseline:
    model:
      path: "meta-llama/Llama-2-7b-chat-hf"
      use_fast: true
    quantization:
      load_in_4bit: false
      load_in_8bit: true
    generation:
      max_length: 512
      temperature: 0.7
      top_p: 0.9

  judge:
    model:
      path: "meta-llama/Llama-2-7b-judge-hf"
    generation:
      max_length: 1024
      temperature: 0.7
      top_p: 0.9