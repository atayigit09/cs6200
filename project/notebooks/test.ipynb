{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS device not found.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print (x)\n",
    "else:\n",
    "    print (\"MPS device not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "<class 'int'>\n",
      "question\n",
      "Consider the following statement: \"0-dimensional biomaterials lack inductive properties.\" Is it right? Present fact-based arguments about the statement.\n",
      "id\n",
      "<class 'int'>\n",
      "question\n",
      "Do you agree with the claim that \"1 in 5 million in UK have abnormal PrP positivity.\"? Provide factual statements about the claim.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import asyncio\n",
    "import yaml\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Get the parent directory\n",
    "parent_directory = os.path.abspath(os.path.join(current_directory, os.pardir))\n",
    "\n",
    "# Append the parent directory to sys.path\n",
    "sys.path.append(parent_directory)\n",
    "\n",
    "\n",
    "from models.evaluator import EvalLLM  # Replace 'some_module' with the actual module name\n",
    "\n",
    "from evaluation.pipeline import  QuestionDataset\n",
    "\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "# Get the absolute path of the parent directory\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "config_path = os.path.join(parent_dir, \"data\", \"Halueval2\",\"test.json\")\n",
    "\n",
    "\n",
    "dataset = QuestionDataset(config_path)\n",
    "\n",
    "\n",
    "for id, question in dataset:\n",
    "    print(\"id\")\n",
    "    print(type(id))\n",
    "    print(\"question\")\n",
    "    print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "models.base_model.BaselineLLaMA"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Get the parent directory\n",
    "parent_directory = os.path.abspath(os.path.join(current_directory, os.pardir))\n",
    "\n",
    "# Append the parent directory to sys.path\n",
    "sys.path.append(parent_directory)\n",
    "\n",
    "\n",
    "\n",
    "modellib = importlib.import_module(\"models.base_model\")\n",
    "\n",
    "for name, cls in modellib.__dict__.items():\n",
    "        if name.lower() == \"BaselineLLaMA\".lower():\n",
    "            model = cls\n",
    "\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'device': 'mps', 'model': {'model_id': 'meta-llama/Llama-3.2-1B-Instruct', 'use_fast': True}, 'quantization': {'load_in_8bit': False, 'load_in_4bit': False}, 'generation': {'max_length': 100, 'temperature': 0.7, 'top_p': 0.9}}\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import os\n",
    "\n",
    "# Get the absolute path of the parent directory\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "config_path = os.path.join(parent_dir, \"configs\", \"test_llm.yaml\")\n",
    "\n",
    "# Load the YAML file\n",
    "with open(config_path, \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# Print to verify\n",
    "print(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
